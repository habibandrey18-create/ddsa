# main_worker.py - –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
"""
Main Worker for the Advanced Yandex.Market Bot Architecture

Features:
- Smart search with offset per keyword
- Product validation and quality filtering
- Content generation with templates and CTA rotation
- Publish buffer with Redis queue
- Metrics and CTR tracking
- Price alerts and brand limits
- Postgres + Redis persistence
"""

import asyncio
import logging
import signal
import sys
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import src.config as config

# Services
from src.services.smart_search_service import get_smart_search_service
from src.services.validator_service import get_product_validator
from src.services.content_service import get_content_service
from src.services.publish_service import get_publish_service
from src.services.metrics_service import get_metrics_service
from src.core.database import get_postgres_db
from src.core.redis_cache import get_redis_cache

logger = logging.getLogger(__name__)

class MainWorker:
    """–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –±–æ—Ç–∞"""

    def __init__(self):
        self.running = False

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å—ã
        self.db = get_postgres_db() if config.USE_POSTGRES else None
        self.redis = get_redis_cache() if config.USE_REDIS else None

        self.smart_search = get_smart_search_service()
        self.validator = get_product_validator()
        self.content_service = get_content_service()
        self.publish_service = get_publish_service()
        self.metrics_service = get_metrics_service()

        # –ó–∞–¥–∞—á–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        self.tasks: List[asyncio.Task] = []

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'start_time': None,
            'cycles_completed': 0,
            'products_found': 0,
            'products_published': 0,
            'products_rejected': 0,
            'search_errors': 0,
            'publish_errors': 0
        }

    async def start(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã"""
        if self.running:
            logger.warning("Worker already running")
            return

        self.running = True
        self.stats['start_time'] = datetime.utcnow()

        logger.info("üöÄ Starting Advanced Yandex.Market Bot Worker")

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            await self._check_connections()

            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã
            await self._start_background_services()

            # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª
            await self._main_loop()

        except Exception as e:
            logger.error(f"Critical error in main worker: {e}")
            await self.stop()
            raise
        finally:
            await self.stop()

    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã"""
        if not self.running:
            return

        logger.info("üõë Stopping Advanced Yandex.Market Bot Worker")
        self.running = False

        # –û—Ç–º–µ–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        for task in self.tasks:
            if not task.done():
                task.cancel()

        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á
        await asyncio.gather(*self.tasks, return_exceptions=True)

        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Ä–≤–∏—Å—ã
        try:
            await self.publish_service.stop_publisher()
        except Exception as e:
            logger.error(f"Error stopping publish service: {e}")

        try:
            await self.smart_search.close_session()
        except Exception as e:
            logger.error(f"Error closing smart search session: {e}")

        try:
            await self.validator.close_session()
        except Exception as e:
            logger.error(f"Error closing validator session: {e}")

        self.tasks.clear()
        logger.info("‚úÖ All services stopped")

    async def _check_connections(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîç Checking database connections...")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (dev/prod)
        is_production = getattr(config, 'ENVIRONMENT', 'dev').lower() == 'prod'
        is_production = is_production or not getattr(config, 'DEBUG_MODE', True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Postgres
        if config.USE_POSTGRES:
            try:
                # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                test_result = self.db.get_search_key("test")
                logger.info("‚úÖ Postgres connection OK")
            except Exception as e:
                logger.error(f"‚ùå Postgres connection failed: {e}")
                raise

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Redis - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ
        if config.USE_REDIS:
            try:
                if self.redis.health_check():
                    logger.info("‚úÖ Redis connection OK")
                else:
                    raise Exception("Redis health check failed")
            except Exception as e:
                logger.error(f"‚ùå Redis connection failed: {e}")
                raise
        elif is_production:
            # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ Redis –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            raise RuntimeError(
                "Redis is required in production environment. "
                "Set USE_REDIS=true and configure Redis connection in your environment variables."
            )
        else:
            logger.warning("‚ö†Ô∏è  Redis not enabled - using in-memory queues (not recommended for production)")

        logger.info("‚úÖ All database connections verified")

    async def _start_background_services(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–æ–Ω–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã"""
        logger.info("üîÑ Starting background services...")

        # –ó–∞–ø—É—Å–∫–∞–µ–º publisher
        await self.publish_service.start_publisher()
        logger.info("‚úÖ Publish service started")

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        search_task = asyncio.create_task(self._search_cycle())
        self.tasks.append(search_task)

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
        maintenance_task = asyncio.create_task(self._maintenance_cycle())
        self.tasks.append(maintenance_task)

        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á—É –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤
        reporting_task = asyncio.create_task(self._reporting_cycle())
        self.tasks.append(reporting_task)

        logger.info("‚úÖ Background services started")

    async def _main_loop(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã"""
        logger.info("üîÑ Starting main work loop")

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–∏–≥–Ω–∞–ª–æ–≤
        def signal_handler(signum, frame):
            logger.info(f"Received signal {signum}, initiating graceful shutdown")
            asyncio.create_task(self.stop())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

        try:
            # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª - –ø—Ä–æ—Å—Ç–æ –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            while self.running:
                await asyncio.sleep(1)

                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å
                await self._log_status()

        except asyncio.CancelledError:
            logger.info("Main loop cancelled")
        except Exception as e:
            logger.error(f"Error in main loop: {e}")
            raise

    async def _search_cycle(self):
        """–¶–∏–∫–ª –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        logger.info("üîç Starting search cycle")

        search_interval = 1800  # 30 –º–∏–Ω—É—Ç –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ –ø–æ–∏—Å–∫–∞
        consecutive_errors = 0
        max_consecutive_errors = 5

        while self.running:
            try:
                start_time = datetime.utcnow()
                logger.info("üåê Starting smart search cycle...")

                # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
                result = await self.smart_search.run_smart_search_cycle(max_catalogs=5)

                # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∏—Å–∫–∞
                metrics = self.smart_search.get_metrics()
                logger.info(f"Search metrics: {metrics}")

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self.stats['cycles_completed'] += 1
                self.stats['products_found'] += result.get('total_added', 0)

                duration = (datetime.utcnow() - start_time).total_seconds()
                logger.info(f"‚úÖ Search cycle completed: added={result.get('total_added', 0)}, skipped={result.get('total_skipped', 0)}, time={duration:.1f}s")
                consecutive_errors = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫

            except Exception as e:
                consecutive_errors += 1
                self.stats['search_errors'] += 1
                logger.error(f"Search cycle error ({consecutive_errors}/{max_consecutive_errors}): {e}")

                if consecutive_errors >= max_consecutive_errors:
                    logger.error("Too many consecutive search errors, pausing search cycle")
                    await asyncio.sleep(3600)  # –ü–∞—É–∑–∞ –Ω–∞ —á–∞—Å
                    consecutive_errors = 0
                    continue

            # –ñ–¥—ë–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
            await asyncio.sleep(search_interval)

    async def _maintenance_cycle(self):
        """–¶–∏–∫–ª –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∏ –æ—á–∏—Å—Ç–∫–∏"""
        logger.info("üßπ Starting maintenance cycle")

        maintenance_interval = 3600  # 1 —á–∞—Å

        while self.running:
            try:
                logger.info("üßπ Running maintenance tasks...")

                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∫—ç—à–∏ –≤ Redis
                if self.redis:
                    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (—Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤)
                    # TODO: –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ –æ—á–∏—Å—Ç–∫–∏ –≤ redis_cache.py

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ Redis
                    if not self.redis.health_check():
                        logger.warning("Redis health check failed")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã –≤ Postgres (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                # TODO: –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ database_postgres.py

                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ª–æ–≥–∏ –º–µ—Ç—Ä–∏–∫ (—Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π)
                cutoff_date = datetime.utcnow() - timedelta(days=90)
                # TODO: –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ –æ—á–∏—Å—Ç–∫–∏ –≤ database_postgres.py

                logger.info("‚úÖ Maintenance tasks completed")

            except Exception as e:
                logger.error(f"Maintenance cycle error: {e}")

            await asyncio.sleep(maintenance_interval)

    async def _reporting_cycle(self):
        """–¶–∏–∫–ª —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤"""
        logger.info("üìä Starting reporting cycle")

        report_interval = 86400  # 24 —á–∞—Å–∞

        while self.running:
            try:
                logger.info("üìä Generating performance report...")

                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—á—ë—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                report = self.metrics_service.get_performance_report(days=7)

                # –õ–æ–≥–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                overall_ctr = report.get('overall', {}).get('overall_ctr', 0)
                total_posts = report.get('overall', {}).get('total_posts', 0)

                logger.info(f"üìä Performance Report (7 days):")
                logger.info(f"   Posts: {total_posts}")
                logger.info(f"   Overall CTR: {overall_ctr:.2f}%")

                # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ø –±—Ä–µ–Ω–¥–æ–≤ –ø–æ CTR
                brand_ctr = report.get('overall', {}).get('brand_ctr', [])
                if brand_ctr:
                    top_brand = brand_ctr[0]
                    logger.info(f"   Top Brand: {top_brand['brand']} ({top_brand['ctr']:.2f}%)")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á—ë—Ç –≤ —Ñ–∞–π–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                # self._save_report_to_file(report)

            except Exception as e:
                logger.error(f"Reporting cycle error: {e}")

            await asyncio.sleep(report_interval)

    async def _log_status(self):
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å —Ä–∞–∑ –≤ 5 –º–∏–Ω—É—Ç"""
        if not hasattr(self, '_last_status_log'):
            self._last_status_log = datetime.utcnow()

        if (datetime.utcnow() - self._last_status_log).total_seconds() >= 300:  # 5 –º–∏–Ω—É—Ç
            uptime = datetime.utcnow() - self.stats['start_time']

            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏
            queue_stats = self.publish_service.get_queue_stats()

            logger.info("üìà Status Update:")
            logger.info(f"   Uptime: {uptime}")
            logger.info(f"   Search cycles: {self.stats['cycles_completed']}")
            logger.info(f"   Products found: {self.stats['products_found']}")
            logger.info(f"   Queue size: {queue_stats.get('queue_size', 0)}")
            logger.info(f"   Publisher running: {queue_stats.get('publisher_running', False)}")

            self._last_status_log = datetime.utcnow()

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã"""
        uptime = None
        if self.stats['start_time']:
            uptime = (datetime.utcnow() - self.stats['start_time']).total_seconds()

        return {
            'running': self.running,
            'uptime_seconds': uptime,
            'cycles_completed': self.stats['cycles_completed'],
            'products_found': self.stats['products_found'],
            'products_published': self.stats['products_published'],
            'products_rejected': self.stats['products_rejected'],
            'search_errors': self.stats['search_errors'],
            'publish_errors': self.stats['publish_errors'],
            'queue_stats': self.publish_service.get_queue_stats() if hasattr(self.publish_service, 'get_queue_stats') else {},
            'services_health': self._check_services_health()
        }

    def _check_services_health(self) -> Dict[str, bool]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ —Å–µ—Ä–≤–∏—Å–æ–≤"""
        health = {}

        # Postgres
        try:
            self.db.get_search_key("health_check")
            health['postgres'] = True
        except:
            health['postgres'] = False

        # Redis
        if self.redis:
            health['redis'] = self.redis.health_check()
        else:
            health['redis'] = None  # Not used

        # Services
        health['smart_search'] = True  # Always available
        health['validator'] = True     # Always available
        health['content_service'] = True  # Always available
        health['publish_service'] = self.publish_service._running if hasattr(self.publish_service, '_running') else False
        health['metrics_service'] = True  # Always available

        return health

    async def manual_search(self, keywords: List[str] = None, max_pages: int = 1) -> Dict:
        """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info(f"üîç Manual search requested for keywords: {keywords or 'default'}")

        try:
            result = await self.smart_search.run_smart_search_cycle(
                max_catalogs=min(max_pages, 5)  # max_catalogs –≤–º–µ—Å—Ç–æ max_pages
            )

            logger.info(f"‚úÖ Manual search completed: {result}")
            return result

        except Exception as e:
            logger.error(f"‚ùå Manual search failed: {e}")
            return {'error': str(e)}

    async def force_publish_cycle(self) -> Dict:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ü–∏–∫–ª –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info("üöÄ Force publish cycle requested")

        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏
            items = self.redis.dequeue_publish_items(count=1) if self.redis else []

            if not items:
                return {'message': 'No items in queue'}

            result = {'published': 0, 'failed': 0}

            # –ü—É–±–ª–∏–∫—É–µ–º —ç–ª–µ–º–µ–Ω—Ç
            for item in items:
                try:
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                    # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
                    logger.info(f"Would publish: {item.get('title', 'Unknown')}")
                    result['published'] += 1
                except Exception as e:
                    logger.error(f"Failed to publish item: {e}")
                    result['failed'] += 1

            return result

        except Exception as e:
            logger.error(f"Force publish cycle failed: {e}")
            return {'error': str(e)}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_main_worker = None

def get_main_worker() -> MainWorker:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–ª–∞–≤–Ω–æ–≥–æ worker'–∞"""
    global _main_worker
    if _main_worker is None:
        _main_worker = MainWorker()
    return _main_worker

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ worker'–∞"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    worker = get_main_worker()

    try:
        await worker.start()
    except KeyboardInterrupt:
        logger.info("Received keyboard interrupt")
    except Exception as e:
        logger.error(f"Worker failed: {e}")
        sys.exit(1)
    finally:
        await worker.stop()

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ worker'–∞
    asyncio.run(main())
