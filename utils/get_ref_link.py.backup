# utils/get_ref_link.py
"""
Yandex Market Link Generator - Network-first approach with button click fallback
Rewritten as a class-based solution for better reliability
"""
import asyncio
import logging
import re
import os
import json
from typing import Optional, Dict, Any, List
from datetime import datetime
from urllib.parse import urlparse, parse_qs

# Import captcha solver
try:
    from .captcha_solver import CaptchaSolver, detect_captcha_on_page, solve_captcha_in_browser
    CAPTCHA_SOLVER_AVAILABLE = True
except ImportError:
    CAPTCHA_SOLVER_AVAILABLE = False
    logger.warning("Captcha solver not available")

logger = logging.getLogger(__name__)

# Regex patterns for link extraction
CC_LINK_PATTERN = re.compile(r'https?://market\.yandex\.ru/cc/[A-Za-z0-9_-]+')
SHORT_URL_PATTERN = re.compile(r'https?://[^\s"\'<>]+/cc/[A-Za-z0-9_-]+')


class YandexMarketLinkGen:
    """
    Yandex Market Link Generator class.
    Primary method: Network interception for shortUrl or /cc/ links.
    Fallback method: Button clicking with retry attempts.
    """
    
    def __init__(
        self,
        headless: bool = False,
        timeout_ms: int = 30000,
        debug: bool = True,
        max_retries: int = 3
    ):
        """
        Initialize the link generator.
        
        Args:
            headless: Run browser in headless mode
            timeout_ms: Timeout in milliseconds
            debug: Enable debug mode (screenshots, HTML dumps)
            max_retries: Maximum retry attempts for button clicking
        """
        self.headless = headless
        self.timeout_ms = timeout_ms
        self.debug = debug
        self.max_retries = max_retries
        
        # Debug directory
        self.debug_dir = os.path.join(
            os.path.dirname(__file__), "..", "debug"
        )
        os.makedirs(self.debug_dir, exist_ok=True)
        
        # Network interception data
        self.captured_responses: List[Dict[str, Any]] = []
        self.found_links: set = set()
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Cookies file path
        self.cookies_file = os.path.join(
            os.path.dirname(__file__), "..", "cookies.json"
        )
        
        # Captcha solver (optional)
        self.captcha_solver = None
        if CAPTCHA_SOLVER_AVAILABLE:
            try:
                self.captcha_solver = CaptchaSolver()
                if self.captcha_solver.api_key:
                    logger.info("âœ… Captcha solver initialized")
            except Exception as e:
                logger.warning(f"Failed to initialize captcha solver: {e}")
    
    def _load_cookies_from_file(self) -> Optional[Dict]:
        """Load cookies from file if exists."""
        if os.path.exists(self.cookies_file):
            try:
                with open(self.cookies_file, 'r', encoding='utf-8') as f:
                    storage_state = json.load(f)
                    return storage_state
            except Exception as e:
                logger.warning(f"Failed to load cookies: {e}")
        return None
    
    async def interactive_login(self) -> bool:
        """
        Interactive login - manual login in browser, then save cookies.
        Use this ONCE to authenticate, then use saved cookies for all operations.
        """
        logger.info("ðŸ” Starting interactive login...")
        
        try:
            from playwright.async_api import async_playwright
        except ImportError:
            raise Exception("Playwright not installed. Run: pip install playwright && python -m playwright install chromium")
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)
            page = await browser.new_page()
            
            try:
                # Open with large timeout
                logger.info("ðŸ“„ Opening passport.yandex.ru...")
                await page.goto(
                    'https://passport.yandex.ru/auth?origin=market_web&retpath=https://market.yandex.ru',
                    timeout=120000,  # 2 minutes
                    wait_until='domcontentloaded'
                )
                
                # Wait 5 minutes for manual login
                logger.info("â³ Ð–Ð´ÐµÐ¼ Ñ€ÑƒÑ‡Ð½Ð¾Ð³Ð¾ Ð²Ñ…Ð¾Ð´Ð°... Ð£ Ð²Ð°Ñ ÐµÑÑ‚ÑŒ 5 Ð¼Ð¸Ð½ÑƒÑ‚")
                logger.info("â³ ÐŸÐ¾ÑÐ»Ðµ Ð²Ñ…Ð¾Ð´Ð° Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Enter Ð² ÐºÐ¾Ð½ÑÐ¾Ð»Ð¸...")
                await asyncio.sleep(300)  # 5 minutes
                
                # Check if login was successful
                current_url = page.url
                if 'market.yandex.ru' in current_url or 'passport.yandex.ru' not in current_url:
                    logger.info("âœ… Login successful!")
                    
                    # Save storage state (cookies + localStorage)
                    storage_state = await page.context.storage_state()
                    with open(self.cookies_file, 'w', encoding='utf-8') as f:
                        json.dump(storage_state, f, indent=2)
                    
                    logger.info(f"âœ… Cookies saved to {self.cookies_file}")
                    await browser.close()
                    return True
                else:
                    logger.warning("âš ï¸ Login may not be complete. Please try again.")
                    await browser.close()
                    return False
            
            except Exception as e:
                logger.error(f"Login error: {e}")
                await browser.close()
                return False
    
    async def generate_cc_link(self, url: str) -> Optional[str]:
        """
        Generate FRESH CC link through browser (using saved cookies).
        This is the main function that generates a NEW CC before publishing.
        """
        # Step 1: Try browser method (with cookies)
        try:
            cc_link = await self._get_cc_from_browser(url)
            if cc_link:
                logger.info(f"âœ… Got fresh CC via browser: {cc_link}")
                return cc_link
        except Exception as e:
            logger.warning(f"Browser method failed: {e}")
        
        # Step 2: Fallback - use regular generate_link
        try:
            cookies_data = self._load_cookies_from_file()
            cookies = None
            if cookies_data and 'cookies' in cookies_data:
                cookies = cookies_data['cookies']
            
            cc_link = await self.generate_link(url, cookies)
            if cc_link:
                logger.info(f"âœ… Got CC via generate_link: {cc_link}")
                return cc_link
        except Exception as e:
            logger.warning(f"generate_link method failed: {e}")
        
        # Step 3: If everything failed
        logger.error("âŒ Could not generate CC - asking user to re-login")
        return None
    
    async def _get_cc_from_browser(self, url: str) -> Optional[str]:
        """
        Generate CC through browser (using saved cookies).
        Opens product page, clicks Share button, extracts CC link.
        """
        browser = None
        try:
            try:
                from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout
            except ImportError:
                raise Exception("Playwright not installed")
            
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,
                    args=['--disable-blink-features=AutomationControlled']
                )
                
                # Load saved cookies
                storage_state = self._load_cookies_from_file()
                context_options = {
                    'viewport': {'width': 1920, 'height': 1080},
                    'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                    'locale': 'ru-RU',
                    'timezone_id': 'Europe/Moscow',
                }
                
                if storage_state:
                    context_options['storage_state'] = self.cookies_file
                    logger.info("âœ… Using saved cookies")
                
                context = await browser.new_context(**context_options)
                page = await context.new_page()
                
                # Anti-bot measures
                await page.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                """)
                
                # Open product page
                logger.info(f"ðŸ“„ Opening product page: {url}")
                await page.goto(url, wait_until='load', timeout=20000)
                await page.wait_for_load_state('networkidle')
                
                # Check for captcha
                if CAPTCHA_SOLVER_AVAILABLE:
                    captcha_info = await detect_captcha_on_page(page)
                    if captcha_info and captcha_info.get("detected"):
                        logger.warning("ðŸš« CAPTCHA detected! Attempting to solve...")
                        solved = await solve_captcha_in_browser(page, captcha_info, self.captcha_solver)
                        if not solved:
                            logger.error("âŒ Failed to solve captcha. Please solve manually or check API key.")
                            await browser.close()
                            return None
                        logger.info("âœ… CAPTCHA solved, continuing...")
                        await asyncio.sleep(2.0)  # Wait after solving captcha
                
                # Find and click Share button
                share_selectors = [
                    'button[aria-label*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
                    'button:has-text("ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ")',
                    'a[title*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
                    '[data-testid*="share"]',
                ]
                
                share_button = None
                for selector in share_selectors:
                    try:
                        share_button = await page.query_selector(selector)
                        if share_button:
                            logger.info(f"âœ… Found share button: {selector}")
                            break
                    except Exception:
                        continue
                
                if not share_button:
                    logger.error("âŒ Share button not found")
                    await browser.close()
                    return None
                
                # Click share button
                await share_button.click(timeout=5000)
                
                # Wait for modal
                try:
                    await page.wait_for_selector('.Modal, [data-test-id="share-modal"], input[value*="market.yandex.ru/cc/"]', timeout=5000)
                except Exception:
                    logger.warning("âš ï¸ Modal not found, trying to find input directly")
                
                # Find input field with CC link
                input_selectors = [
                    'input[value*="market.yandex.ru/cc/"]',
                    'input[type="text"][value*="/cc/"]',
                    'input[readonly][value*="/cc/"]',
                ]
                
                cc_url = None
                for selector in input_selectors:
                    try:
                        input_field = await page.query_selector(selector)
                        if input_field:
                            cc_url = await input_field.input_value()
                            if cc_url:
                                logger.info(f"âœ… Found CC link in input: {cc_url}")
                                break
                    except Exception:
                        continue
                
                # If not found in input, try to extract from page
                if not cc_url:
                    page_content = await page.content()
                    cc_url = self._extract_cc_link(page_content)
                    if cc_url:
                        logger.info(f"âœ… Found CC link in page content: {cc_url}")
                
                await browser.close()
                return cc_url
                
        except Exception as e:
            logger.error(f"Browser CC generation failed: {e}")
            if browser:
                await browser.close()
            return None
    
    def _extract_cc_link(self, text: str) -> Optional[str]:
        """Extract cc/ link from text."""
        if not text:
            return None
        match = CC_LINK_PATTERN.search(text)
        if match:
            return match.group(0).split('?')[0]
        return None
    
    async def _save_debug_artifacts(
        self,
        page,
        error_msg: str = "",
        prefix: str = "error"
    ):
        """Save screenshots and HTML to debug folder."""
        if not self.debug:
            return
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Save HTML
            html_path = os.path.join(
                self.debug_dir,
                f"{prefix}_page_{timestamp}.html"
            )
            try:
                html_content = await page.content()
                with open(html_path, "w", encoding="utf-8") as f:
                    f.write(f"<!-- Error: {error_msg} -->\n")
                    f.write(f"<!-- Timestamp: {timestamp} -->\n")
                    f.write(html_content)
                logger.info(f"ðŸ’¾ Saved HTML: {html_path}")
            except Exception as e:
                logger.warning(f"Failed to save HTML: {e}")
            
            # Save screenshot
            screenshot_path = os.path.join(
                self.debug_dir,
                f"{prefix}_screenshot_{timestamp}.png"
            )
            try:
                await page.screenshot(
                    path=screenshot_path,
                    full_page=True
                )
                logger.info(f"ðŸ’¾ Saved screenshot: {screenshot_path}")
            except Exception as e:
                logger.warning(f"Failed to save screenshot: {e}")
            
            # Save network log
            network_log_path = os.path.join(
                self.debug_dir,
                f"{prefix}_network_{timestamp}.json"
            )
            try:
                with open(network_log_path, "w", encoding="utf-8") as f:
                    json.dump(self.captured_responses, f, indent=2, ensure_ascii=False)
                logger.info(f"ðŸ’¾ Saved network log: {network_log_path}")
            except Exception as e:
                logger.warning(f"Failed to save network log: {e}")
                
        except Exception as e:
            logger.error(f"Failed to save debug artifacts: {e}")
    
    async def _wait_for_api_response(self, page, action_func):
        """
        Wait for API response after performing an action (e.g., clicking Share button).
        This is the PRIMARY method for link extraction.
        
        Args:
            page: Playwright page object
            action_func: Async function to execute (e.g., clicking Share button)
            
        Returns:
            Optional[str]: Extracted link or None
        """
        try:
            # Wait for API response from Yandex Market
            async with page.expect_response(
                lambda response: (
                    "market.yandex.ru/api/" in response.url or
                    "market.yandex.ru" in response.url and "/api/" in response.url or
                    "platform-api.yandex.ru" in response.url or
                    response.url.endswith("/share") or
                    "/share" in response.url or
                    "/cc/" in response.url
                ) and response.status == 200,
                timeout=10000
            ) as response_info:
                # Execute the action (e.g., click Share button)
                await action_func()
            
            # Get the response
            response = await response_info.value
            url_str = str(response.url)
            
            logger.info(f"ðŸŒ API response received: {url_str[:150]}...")
            
            # Check if response URL contains /cc/
            cc_link = self._extract_cc_link(url_str)
            if cc_link:
                logger.info(f"âœ… Found /cc/ link in response URL: {cc_link}")
                return cc_link
            
            # Try to parse JSON response
            try:
                content_type = response.headers.get('content-type', '')
                
                if 'application/json' in content_type:
                    response_data = await response.json()
                    
                    # Store for debugging
                    self.captured_responses.append({
                        "url": url_str,
                        "status": response.status,
                        "content_type": content_type,
                        "data": response_data,
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    # Look for shortUrl key
                    if isinstance(response_data, dict):
                        # Check common keys
                        short_url = (
                            response_data.get('shortUrl') or
                            response_data.get('short_url') or
                            response_data.get('url') or
                            response_data.get('link') or
                            response_data.get('href') or
                            response_data.get('data', {}).get('shortUrl') or
                            response_data.get('result', {}).get('shortUrl')
                        )
                        
                        if short_url:
                            cc_link = self._extract_cc_link(short_url)
                            if cc_link:
                                logger.info(f"âœ… Found shortUrl in JSON: {cc_link}")
                                return cc_link
                        
                        # Search recursively in all string values
                        def search_dict(d, depth=0, path=""):
                            if depth > 10:  # Prevent infinite recursion
                                return None
                            if isinstance(d, dict):
                                for k, v in d.items():
                                    if isinstance(v, str):
                                        cc_link = self._extract_cc_link(v)
                                        if cc_link:
                                            logger.info(f"âœ… Found /cc/ link in JSON at {path}.{k}: {cc_link}")
                                            return cc_link
                                    elif isinstance(v, (dict, list)):
                                        result = search_dict(v, depth + 1, f"{path}.{k}")
                                        if result:
                                            return result
                            elif isinstance(d, list):
                                for i, item in enumerate(d):
                                    if isinstance(item, str):
                                        cc_link = self._extract_cc_link(item)
                                        if cc_link:
                                            logger.info(f"âœ… Found /cc/ link in JSON array at {path}[{i}]: {cc_link}")
                                            return cc_link
                                    elif isinstance(item, (dict, list)):
                                        result = search_dict(item, depth + 1, f"{path}[{i}]")
                                        if result:
                                            return result
                            return None
                        
                        found_link = search_dict(response_data)
                        if found_link:
                            return found_link
                
                # Try text response
                try:
                    text = await response.text()
                    cc_link = self._extract_cc_link(text)
                    if cc_link:
                        logger.info(f"âœ… Found /cc/ link in text response: {cc_link}")
                        return cc_link
                    
                    self.captured_responses.append({
                        "url": url_str,
                        "status": response.status,
                        "content_type": content_type,
                        "text_snippet": text[:1000],
                        "timestamp": datetime.now().isoformat()
                    })
                except Exception:
                    pass
                
            except (ValueError, TypeError, json.JSONDecodeError) as e:
                logger.debug(f"Failed to parse JSON response: {e}")
                # Try text
                try:
                    text = await response.text()
                    cc_link = self._extract_cc_link(text)
                    if cc_link:
                        logger.info(f"âœ… Found /cc/ link in text response: {cc_link}")
                        return cc_link
                except Exception:
                    pass
            
            # Check for redirects
            if 300 <= response.status < 400:
                location = response.headers.get('location', '')
                if location:
                    cc_link = self._extract_cc_link(location)
                    if cc_link:
                        logger.info(f"âœ… Found /cc/ link in redirect: {cc_link}")
                        return cc_link
            
            logger.warning(f"âš ï¸ API response received but no /cc/ link found")
            return None
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to wait for API response: {e}")
            return None
    
    async def _click_share_button(self, page, retry_count: int = 0) -> bool:
        """
        Click the "Share" button with multiple strategies.
        Returns True if click was successful.
        """
        share_selectors = [
            'button:has-text("ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ")',
            'button[aria-label*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
            'a[title*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
            '[data-testid*="share"]',
            '[class*="share"]',
            '[class*="Share"]'
        ]
        
        share_button = None
        for selector in share_selectors:
            try:
                share_button = await page.query_selector(selector)
                if share_button:
                    logger.info(f"âœ… Found share button: {selector}")
                    break
            except Exception:
                continue
        
        # Search in frames
        if not share_button:
            for frame in page.frames:
                try:
                    for selector in share_selectors:
                        share_button = await frame.query_selector(selector)
                        if share_button:
                            logger.info(f"âœ… Found share button in frame: {selector}")
                            break
                    if share_button:
                        break
                except Exception:
                    continue
        
        if not share_button:
            logger.error("âŒ Share button not found")
            return False
        
        # Try multiple click strategies
        async def strategy1():
            await share_button.click(timeout=5000)
        
        async def strategy2():
            await share_button.scroll_into_view_if_needed()
            await asyncio.sleep(0.3)
            await share_button.click(timeout=5000)
        
        async def strategy3():
            await self._click_with_mouse(page, share_button)
        
        async def strategy4():
            await share_button.evaluate("""
                (el) => {
                    el.scrollIntoView({block: 'center'});
                    const event = new MouseEvent('click', {
                        bubbles: true, cancelable: true, composed: true
                    });
                    el.dispatchEvent(event);
                }
            """)
        
        async def strategy5():
            await share_button.evaluate("(el) => el.click()")
        
        strategies = [
            ("element.click()", strategy1),
            ("scrollIntoView + click", strategy2),
            ("mouse events", strategy3),
            ("JS dispatchEvent", strategy4),
            ("JS element.click()", strategy5),
        ]
        
        for strategy_name, strategy_func in strategies:
            try:
                logger.info(f"  ðŸ”„ Trying click strategy: {strategy_name}")
                await strategy_func()
                await asyncio.sleep(0.5)  # Wait for modal to appear
                logger.info(f"âœ… Click successful with: {strategy_name}")
                return True
            except Exception as e:
                logger.warning(f"  âŒ Strategy {strategy_name} failed: {e}")
                continue
        
        logger.error("âŒ All click strategies failed")
        return False
    
    async def _click_with_mouse(self, page, element):
        """Click using mouse events."""
        box = await element.bounding_box()
        if box:
            await page.mouse.move(
                box['x'] + box['width'] / 2,
                box['y'] + box['height'] / 2
            )
            await asyncio.sleep(0.1)
            await page.mouse.down()
            await asyncio.sleep(0.1)
            await page.mouse.up()
            await asyncio.sleep(0.2)
    
    async def _extract_link_from_modal(self, page) -> Optional[str]:
        """Extract link from modal dialog."""
        modal_selectors = [
            'div[role="dialog"]',
            '.share-modal',
            '.modal',
            '[class*="modal"]',
            '[class*="Modal"]'
        ]
        
        modal = None
        for selector in modal_selectors:
            try:
                modal = await page.query_selector(selector)
                if modal:
                    logger.info(f"âœ… Found modal: {selector}")
                    break
            except Exception:
                continue
        
        if not modal:
            return None
        
        # Search in modal
        try:
            # Check inputs
            inputs = await modal.query_selector_all('input, textarea')
            for inp in inputs:
                try:
                    value = await inp.input_value()
                    if value:
                        link = self._extract_cc_link(value)
                        if link:
                            logger.info(f"âœ… Found link in modal input: {link}")
                            return link
                except Exception:
                    continue
            
            # Check text content
            text = await modal.inner_text()
            link = self._extract_cc_link(text)
            if link:
                logger.info(f"âœ… Found link in modal text: {link}")
                return link
            
            # Check data attributes
            data_attrs = await modal.evaluate("""
                (modal) => {
                    const results = [];
                    const allElements = modal.querySelectorAll('*');
                    for (let el of allElements) {
                        for (let attr of el.attributes) {
                            if (attr.name.startsWith('data-')) {
                                results.push(attr.value);
                            }
                        }
                    }
                    return results;
                }
            """)
            for attr_val in data_attrs:
                link = self._extract_cc_link(attr_val)
                if link:
                    logger.info(f"âœ… Found link in modal data-attr: {link}")
                    return link
        
        except Exception as e:
            logger.debug(f"Error extracting from modal: {e}")
        
        return None
    
    async def _extract_link_from_clipboard(self, page) -> Optional[str]:
        """Extract link from clipboard."""
        try:
            clipboard_content = await page.evaluate("""
                async () => {
                    try {
                        if (navigator.clipboard && navigator.clipboard.readText) {
                            return await navigator.clipboard.readText();
                        }
                    } catch (e) {}
                    return null;
                }
            """)
            
            if clipboard_content:
                link = self._extract_cc_link(clipboard_content)
                if link:
                    logger.info(f"âœ… Found link in clipboard: {link}")
                    return link
        except Exception as e:
            logger.debug(f"Clipboard read failed: {e}")
        
        return None
    
    async def generate_link(
        self,
        url: str,
        cookies: Optional[List[Dict]] = None
    ) -> str:
        """
        Generate partner link for Yandex Market product.
        
        Primary method: Network interception (listens for shortUrl or /cc/ in responses).
        Fallback method: Button clicking with retry attempts.
        
        Args:
            url: Product URL
            cookies: Optional cookies for authentication (if None, will try to load from file)
            
        Returns:
            Clean partner link (https://market.yandex.ru/cc/XXXXX)
            
        Raises:
            Exception: If link cannot be generated after all attempts
        """
        # Check if URL already contains /cc/
        cc_match = re.search(r'/cc/([A-Za-z0-9_-]+)', url)
        if cc_match:
            cc_code = cc_match.group(1)
            ref_link = f"https://market.yandex.ru/cc/{cc_code}"
            logger.info(f"âœ… URL already contains /cc/ code: {cc_code}")
            return ref_link
        
        try:
            from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout
        except ImportError:
            raise Exception("Playwright not installed. Run: pip install playwright && python -m playwright install chromium")
        
        # Load cookies from file if not provided
        if cookies is None:
            storage_state = self._load_cookies_from_file()
            if storage_state and 'cookies' in storage_state:
                cookies = storage_state['cookies']
                logger.info("âœ… Loaded cookies from file")
        
        async with async_playwright() as p:
            launch_options = {
                "headless": self.headless and not self.debug,
                "slow_mo": 250 if self.debug else 0,
                "args": [
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage',
                    '--no-sandbox',
                    '--lang=ru-RU,ru',
                ]
            }
            
            browser = await p.chromium.launch(**launch_options)
            
            # Use storage_state if cookies file exists
            context_options = {
                'viewport': {'width': 1920, 'height': 1080},
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
                'locale': 'ru-RU',
                'timezone_id': 'Europe/Moscow',
                'permissions': ['clipboard-read', 'clipboard-write'],
            }
            
            # Use storage_state if cookies file exists (better than adding cookies manually)
            if os.path.exists(self.cookies_file):
                try:
                    context_options['storage_state'] = self.cookies_file
                    logger.info("âœ… Using storage_state from cookies file")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to use storage_state: {e}")
            
            context = await browser.new_context(**context_options)
            page = await context.new_page()
            
            # Anti-bot measures
            await page.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
            """)
            
            # Add cookies if provided and storage_state wasn't used
            if cookies and 'storage_state' not in context_options:
                try:
                    await context.add_cookies(cookies)
                    logger.info("âœ… Cookies loaded manually")
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to add cookies: {e}")
            
            try:
                # Navigate to page
                logger.info(f"ðŸ“„ Navigating to: {url}")
                try:
                    response = await page.goto(url, wait_until='domcontentloaded', timeout=self.timeout_ms)
                    
                    # Check HTTP status
                    if response:
                        status = response.status
                        if status == 403:
                            logger.error("âŒ 403 Forbidden - Access denied. Possible reasons:")
                            logger.error("   - IP blocked by Yandex")
                            logger.error("   - Too many requests")
                            logger.error("   - Suspicious activity detected")
                            raise Exception("403 Forbidden - Access denied by Yandex")
                        elif status == 429:
                            logger.error("âŒ 429 Too Many Requests - Rate limit exceeded")
                            logger.error("   - Waiting 60 seconds before retry...")
                            await asyncio.sleep(60)
                            raise Exception("429 Too Many Requests - Rate limit exceeded")
                        elif status >= 500:
                            logger.error(f"âŒ Server error {status} - Yandex server issue")
                            raise Exception(f"Server error {status}")
                    
                except Exception as e:
                    if "403" in str(e) or "429" in str(e) or "500" in str(e):
                        raise
                    # Continue if it's a timeout or other navigation error
                    logger.warning(f"Navigation warning: {e}")
                
                await asyncio.sleep(1.0)  # Wait for initial load
                
                # Check for captcha
                if CAPTCHA_SOLVER_AVAILABLE:
                    captcha_info = await detect_captcha_on_page(page)
                    if captcha_info and captcha_info.get("detected"):
                        logger.warning("ðŸš« CAPTCHA detected! Attempting to solve...")
                        solved = await solve_captcha_in_browser(page, captcha_info, self.captcha_solver)
                        if not solved:
                            logger.error("âŒ Failed to solve captcha. Please solve manually or check API key.")
                            raise Exception("CAPTCHA detected and could not be solved automatically")
                        logger.info("âœ… CAPTCHA solved, continuing...")
                        await asyncio.sleep(2.0)  # Wait after solving captcha
                
                # PRIMARY METHOD: Wait for API response after clicking Share button
                logger.info("ðŸŒ Using network interception approach (expect_response)...")
                
                # Find Share button first
                share_selectors = [
                    'button:has-text("ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ")',
                    'button[aria-label*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
                    'button[aria-label="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
                    'a[title*="ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ"]',
                    '[data-testid*="share"]',
                    '[class*="share"]',
                    '[class*="Share"]'
                ]
                
                share_button = None
                for selector in share_selectors:
                    try:
                        share_button = await page.query_selector(selector)
                        if share_button:
                            logger.info(f"âœ… Found share button: {selector}")
                            break
                    except Exception:
                        continue
                
                # Search in frames
                if not share_button:
                    for frame in page.frames:
                        try:
                            for selector in share_selectors:
                                share_button = await frame.query_selector(selector)
                                if share_button:
                                    logger.info(f"âœ… Found share button in frame: {selector}")
                                    break
                            if share_button:
                                break
                        except Exception:
                            continue
                
                if not share_button:
                    raise Exception("Share button not found")
                
                # Try network interception approach with retries
                for attempt in range(self.max_retries):
                    logger.info(f"ðŸ”„ Attempt {attempt + 1}/{self.max_retries} - Network interception...")
                    
                    async def click_share_action():
                        """Action to perform while waiting for API response."""
                        try:
                            await share_button.scroll_into_view_if_needed()
                            await asyncio.sleep(0.3)
                            await share_button.click(timeout=5000)
                        except Exception as e:
                            logger.warning(f"Click failed, trying alternative: {e}")
                            # Try alternative click methods
                            try:
                                await share_button.evaluate("(el) => el.click()")
                            except Exception:
                                await self._click_with_mouse(page, share_button)
                    
                    # Wait for API response after clicking
                    link = await self._wait_for_api_response(page, click_share_action)
                    
                    if link:
                        logger.info(f"âœ… Link found via network interception: {link}")
                        await browser.close()
                        return link
                    
                    # If network interception didn't work, wait a bit and try again
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(2.0)
                
                # FALLBACK: Try button clicking and modal extraction
                logger.info("ðŸ”„ Network interception didn't find link, trying fallback methods...")
                
                for attempt in range(self.max_retries):
                    logger.info(f"ðŸ”„ Fallback attempt {attempt + 1}/{self.max_retries}...")
                    
                    # Click share button
                    share_clicked = await self._click_share_button(page, attempt)
                    if not share_clicked:
                        if attempt < self.max_retries - 1:
                            await asyncio.sleep(2.0)
                            continue
                        else:
                            raise Exception("Failed to click Share button after all retries")
                    
                    # Wait for modal - INCREASED TIMEOUT from 10s to 45s
                    try:
                        await page.wait_for_selector(
                            'div[role="dialog"]',
                            state='visible',
                            timeout=45000  # Increased from 10000 to 45000 (45 seconds)
                        )
                        await asyncio.sleep(1.0)  # Wait for modal content
                    except Exception:
                        logger.warning("âš ï¸ Modal not found, continuing search...")
                    
                    # Try to extract from modal
                    modal_link = await self._extract_link_from_modal(page)
                    if modal_link:
                        logger.info(f"âœ… Link found in modal: {modal_link}")
                        await browser.close()
                        return modal_link
                    
                    # Try to click copy button and check clipboard
                    copy_button_selectors = [
                        'button:has-text("ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÑƒ")',
                        'button:has-text("ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ")',
                        '[aria-label*="ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ"]'
                    ]
                    
                    copy_button = None
                    for selector in copy_button_selectors:
                        try:
                            copy_button = await page.query_selector(selector)
                            if copy_button:
                                logger.info(f"âœ… Found copy button: {selector}")
                                try:
                                    await copy_button.click(timeout=5000)
                                    await asyncio.sleep(0.5)  # Wait for copy to complete
                                except Exception as e:
                                    logger.warning(f"Failed to click copy button: {e}")
                                break
                        except Exception:
                            continue
                    
                    # Try clipboard after copy button click
                    clipboard_link = await self._extract_link_from_clipboard(page)
                    if clipboard_link:
                        logger.info(f"âœ… Link found in clipboard: {clipboard_link}")
                        await browser.close()
                        return clipboard_link
                    
                    # If this attempt failed, wait before retry
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(2.0)
                
                # All attempts failed
                error_msg = "Failed to generate link after all attempts"
                logger.error(f"âŒ {error_msg}")
                await self._save_debug_artifacts(page, error_msg, "failed")
                await browser.close()
                raise Exception(error_msg)
                
            except PlaywrightTimeout as e:
                error_msg = f"Timeout after {self.timeout_ms}ms"
                logger.error(f"âŒ {error_msg}: {e}")
                await self._save_debug_artifacts(page, error_msg, "timeout")
                await browser.close()
                raise Exception(error_msg) from e
                
            except Exception as e:
                error_msg = f"Error during link generation: {e}"
                logger.error(f"âŒ {error_msg}")
                await self._save_debug_artifacts(page, error_msg, "error")
                await browser.close()
                raise


# Backward compatibility function
async def get_cc_link_by_click(
    url: str,
    cookies: Optional[List[Dict]] = None,
    headless: bool = False,
    timeout_ms: int = 30000,
    debug: bool = True,
    max_retries: int = 3,
    base_delay: float = 2.0
) -> Dict[str, Any]:
    """
    Backward compatibility wrapper for the old function signature.
    Returns a dict with 'ref_link' key instead of raising exception.
    
    Now uses generate_cc_link() which generates FRESH CC links via browser.
    """
    try:
        generator = YandexMarketLinkGen(
            headless=headless,
            timeout_ms=timeout_ms,
            debug=debug,
            max_retries=max_retries
        )
        
        # Use new generate_cc_link method for fresh CC
        ref_link = await generator.generate_cc_link(url)
        
        if ref_link:
            return {
                "ref_link": ref_link,
                "flags": ["ok"],
                "note": "Successfully generated fresh CC link"
            }
        else:
            # Fallback to old method
            ref_link = await generator.generate_link(url, cookies)
            return {
                "ref_link": ref_link,
                "flags": ["ok"],
                "note": "Successfully generated link (fallback)"
            }
    except Exception as e:
        logger.error(f"âŒ Failed to generate link: {e}")
        return {
            "ref_link": None,
            "flags": ["error", "ref_not_found"],
            "note": str(e)
        }


# Helper function for interactive login
async def interactive_login(
    headless: bool = False,
    timeout_ms: int = 30000
) -> bool:
    """
    Interactive login function - manual login in browser, then save cookies.
    Use this ONCE to authenticate, then use saved cookies for all operations.
    
    Args:
        headless: Run browser in headless mode (should be False for manual login)
        timeout_ms: Timeout in milliseconds
        
    Returns:
        True if login successful, False otherwise
    """
    generator = YandexMarketLinkGen(
        headless=headless,
        timeout_ms=timeout_ms,
        debug=True
    )
    return await generator.interactive_login()
